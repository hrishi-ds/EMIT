# Path to the preprocessed PhysioNet 2012 dataset.
data_path: './data/pre_processed/physionet_2012_preprocessed.pkl'

# Pretrained model to be fine-tuned, with various hyperparameters used during pretraining.
pt_model: 'EMIT_PHYSIONET_PT_lr_0.0005_err_coef_3_mask_threshold_0.01_insig_prob_0.7'

# Path to the pretrained model weights.
pt_model_weights_path: './pretrained_models/PHYSIONET/${pt_model}.h5'

# Number of training epochs for fine-tuning.
epochs: 100

# List of percentage of labeled data to be used for fine-tuning.
lds: [10, 20, 30, 40, 50]

# Number of times to repeat each experiment.
repeats: 5

# Maximum sequence length for the time series input, same as the pretrained model.
max_seq_length: 791

# Number of unique variables/features in the PhysioNet dataset.
V: 37

# Dimensionality of the input data embedding.
d: 50

# Number of transformer encoder blocks in the model.
N: 2

# Number of attention heads in the model's multi-head attention mechanism.
he: 4

# Dropout rate used for regularization to prevent overfitting.
dropout: 0.4

# Batch size for training the model.
batch_size: 32

# Learning rate for fine-tuning the model.
learning_rate: 0.00005

# Number of epochs to wait before stopping training if validation performance doesn't improve (early stopping).
patience: 10

# Weight decay coefficient for L2 regularization.
weight_decay: 0.0001

# Filename pattern for saving fine-tuned model results and logs, incorporating various hyperparameters.
file_name : '${pt_model}_FT_batchsize${batch_size}_dropout${dropout}_lr${learning_rate}_weight_decay${weight_decay}'

# Path to save the fine-tuning results in a pickle file.
results_path: './results/PHYSIONET/${file_name}.pkl'

# Configuration for logging using Hydra. The log directory is dynamically named based on the current time.
hydra:
  run:
    dir: './logs/hydra_logs/PHYSIONET/FT/${file_name}/${now:%H-%M-%S}'
