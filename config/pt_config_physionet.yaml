# Path to the pretraining dataset.
data_path: './data/pre_training/pretraining_data_physionet_791.npz'

# Threshold for determining significant events during masking.
mask_threshold: 0.01

# Probability of marking insignificant events during masking.
insignificant_prob: 0.7

# Path to the precomputed event masks for pretraining with the specified threshold and probability.
mask_path: './data/pre_training/physionet_event_masks_threshold_${mask_threshold}_insignificant_prob_${insignificant_prob}.npz'

# Batch size for training during pretraining.
batch_size: 128

# Learning rate for the pretraining process.
learning_rate: 0.0005

# Number of training epochs for pretraining.
epochs: 100

# Number of epochs to wait before stopping training if validation performance doesn't improve (early stopping).
patience: 5

# Maximum sequence length for the input time series data during pretraining.
max_len: 791

# Number of unique variables/features in the dataset.
V: 37

# Dimensionality of the input data embedding.
d: 50

# Number of transformer encoder blocks in the model.
N: 2

# Number of attention heads in the model's multi-head attention mechanism.
he: 4

# Dropout rate used for regularization during pretraining to prevent overfitting.
dropout: 0.2

# Weight decay coefficient for L2 regularization.
weight_decay: 0

# Coefficient used for weighing the error from the masked events during pretraining.
error_coefficient: 3

# Number of samples to be processed per epoch during pretraining.
samples_per_epoch: 25600

# Filename pattern for saving the pretrained model.
model_name: './pretrained_models/PHYSIONET/EMIT_PHYSIONET_PT_lr_${learning_rate}_err_coef_${error_coefficient}_mask_threshold_${mask_threshold}_insig_prob_${insignificant_prob}'

# Configuration for logging using Hydra.
hydra:
  run:
    dir: './logs/hydra_logs/PHYSIONET/PT/EMIT_PHYSIONET_PT_lr_${learning_rate}_err_coef_${error_coefficient}_mask_threshold_${mask_threshold}_insig_prob_${insignificant_prob}/${now:%H-%M-%S}'
